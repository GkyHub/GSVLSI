\section{Experiments}\label{sec:exp}

\input{table/device}

Experiments are carried out on the architecture introduced in Section~\ref{sec:hw}, with the scheduling strategy in section~\ref{sec:schedule} applied. We use a behavior level simulator to analyze the memory access and computation energy for running a certain network. Memory access dynamic energy cost, memory static energy cost and computation energy cost are considered in our model.

\subsection{Experiment setup}
The MAC array in the architecture is configured as an $8\times8\times8$ array running at 1GHz. This offers a peak performance of 1TOP/s. 8bit multiplication and 32bit accumulation is adopted in this model. Multiplication and addition energy is scaled down from the data in~\cite{mac_energy} to 22nm technology. 

The above configuration requires the read bandwidth of input/output buffer and weight buffer to be at least 64GB/s. We implement each buffer with 8 banks and each of them should offer 8GB/s read bandwidth. On-chip memory parameters are generated from NVSim~\cite{dong2014nvsim} with different memory size configuration. To achieve enough bandwidth, RRAM buffer bit width is configured as 256bit. 

The external memory parameter is generated from MICRON DDR4 power calculator~\cite{powercalc}. The generated dynamic I/O power is further converted to energy per read or write byte. In our experiment, we use 2 DDR chips as external memory because the bandwidth can support the configured MAC array with proposed schedule strategy and the size is enough. In order to reduce background power overhead, we use the least number of chips. All the detailed data and configuration is shown in Table~\ref{tab:device}. 

The buffer in the accumulator is also considered in our experiments. 4 types of buffer is chosen for design space exploration. Corresponding parameters are generated by NVSim and are shown in Table~\ref{tab:small_buf}.

\input{table/small_buf}

\subsection{Design Space Exploration}
We do experiments on all the combinations of the RAM configurations in Table \ref{tab:device} and \ref{tab:small_buf}, which means $5\times 5\times 5 = 125$ choices for a SRAM or RRAM based accelerator. The three schedule strategies in section~\ref{sec:schedule} is applied to each choice. Figure~\ref{fig:design_space} shows the experimental result with the convolution layers of VGG-11 network for 1 input. The energy cost for computation and DDR leakage is marked. These energy cost is the same for all the designs because the network is fixed and all the designs are computation bounded. So the processing time is a constant to all the designs. In general, the RRAM based design consumes less energy compared with an SRAM design of the same area.

\begin{figure*}[t]
  \centering
  \includegraphics[width=2\columnwidth]{fig/design_space.pdf}
  \caption{Design space exploration on different hardware choices and schedule strategies on the convolution layers of VGG-11 model. (a) SRAM weight buffer design. (b)RRAM weight buffer design.}
  \label{fig:design_space}
\end{figure*}

We examine the effect of the proposed hardware optimization and scheduling strategy. First, the loop order is the key effect to the RRAM based design, as shown in Figure~\ref{fig:design_space}(b). Note that some of the design points with the kernel first loop order are out of the figure because the energy cost is larger than 8000uJ. The large read energy of RRAM dominates the system energy as the capacity of RRAM increases. The reduction in DDR access cannot compensate for this overhead. Even on the smallest design, changing the loop order to pixel first will save at least 1/3 of the system energy cost. A breakdown on the on-chip buffer energy cost is shown in Figure~\ref{fig:breakdown}(a).

\begin{figure*}[t]
  \centering
  \includegraphics[width=2\columnwidth]{fig/breakdown.pdf}
  \caption{(a) On-chip buffer energy cost for a series of designs only differs in accumulation buffer size. (b)DDR access energy cost for a series of designs only differs in RRAM buffer size.}
  \label{fig:breakdown}
\end{figure*}

Second, fixing the weight on-chip helps the hardware fully utilize the on-chip RAM to reduce off-chip data transfer. As can be seen from Figure~\ref{fig:design_space}(b), using the pixel first loop order, the accelerator cannot benefit from larger on-chip buffer with single layer scheduling and cross layer scheduling. By fixing some of the network weights on-chip, the system energy cost is gradually reduced as the on-chip RAM size increases. A detailed breakdown on the DDR transfer cost is shown in Figure~\ref{fig:breakdown}(b).

%\subsection{DDR Access energy optimization}

%DDR access behavior is totally decided by schedule strategy. Here we use the convolution layers of VGG-11 to test the effectiveness of the schedule strategy optimization. Figure~\ref{fig:exp_strategy} shows the experimental results. Input/output buffer is 128KB SRAM and weight buffer varies from 1MB to 16MB RRAM in this experiment. Three levels of optimization is compared: only single layer schedule, cross layer schedule, cross layer schedule and consider fixing weight in buffer. When the weight buffer is small, the main energy saving comes from the cross layer schedule. When the buffer gets larger, fixing weight becomes more important. Up to $20\%$ energy saving can be achieved by the our schedule strategy optimization. From Figure~\ref{fig:exp_strategy}(b), we see that strategy optimization reduces the DDR access energy by $25\%\sim 98\%$ under different memory configurations.

%\subsection{On-chip buffer energy optimization}
%From Figure~\ref{fig:exp_strategy}(a), we see that using a larger buffer is not better. This is caused by the increasing buffer I/O energy and leakage power. An example of energy breakdown is shown in Table~\ref{tab:ene_comp}. Both of the design adopts 1MB SRAM I/O buffer. The SRAM weight buffer is 128KB and the RRAM weight buffer is 1MB. Though the RRAM design has less DDR access energy because of a larger weight buffer, the weight buffer read energy is much higher. This shows the necessity of using buffer, rather than a single register, for accumulation. 

% \input{table/ene_comp}

%We still use the VGG-11 convolution layers to search for an optimal accumulator buffer depth. For each depth choice, we search the optimal buffer size configuration with all the schedule strategy optimization applied. The results are shown in Figure~\ref{fig:exp_buf_depth}. As can be seen from the figure, both methods benefits from the accumulation buffer, but the RRAM design benefits more. With the accumulation buffer, the total on-chip buffer energy cost can be reduced by $86\%$. Combining schedule optimization and accumulation buffer design, we can finally achieve $18\%$ energy reduction by introducing RRAM into on-chip buffer design.