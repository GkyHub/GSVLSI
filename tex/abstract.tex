\begin{abstract}
    
Convolutional Neural Network (CNN) has become the state-of-the-art algorithm for many computer vision tasks. But its high computation complexity and high memory complexity makes it hard to be applied with traditional platforms like CPUs. Memory energy can take up more than 50\% of the system energy, which limits the energy efficiency of CNN processing. The emerging metal-oxide resistive switching random-access memory (RRAM) has been widely studied because of its good properties like high storage density and the compatibility with CMOS. In this paper, a system level energy analysis on the effect of using RRAM as on-chip buffer is carried out for a typical CNN accelerator. With the proposed hardware optimization and schedule strategy optimization, DDR access energy is reduced by $25\%\sim 98\%$ and on-chip buffer dynamic energy is reduced by $86\%$ on a state-of-the-art CNN model.
    
\end{abstract}